{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import OpenAI key with helper function\n",
    "from helper import get_openai_api_key\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A lot of modules use async and we want them to be compatible with Jupyter notebook\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"EDS.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split document into even sized chunks\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LlamaIndex is a Python and Typescript library that enables you to apply LLMs on top of your private or domain-specific data. \n",
    "#Configuring using OpenAI's 3.5 turbo model and model for generating embeddings.\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index is set of metadata over our data.\n",
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes) #return all nodes in index\n",
    "vector_index = VectorStoreIndex(nodes) #index notes via text embeddings, return most similar nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The indexes need to be transformed into query engines which represents a query interface over the stored data.\n",
    "#Unlike a query tool, the query engine is the backend component.\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#While the query engine is the backend component, the query tool is the user-facing app to interact with query engine\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to document\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the document.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM selector to filter and select nodes based on queries\n",
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to MetaGPT.\n",
      "\u001b[0mThe document outlines a randomized controlled trial protocol focusing on patients with hypermobility spectrum disorder (HSD) or hypermobile Ehlers-Danlos syndrome (hEDS) who have long-lasting shoulder complaints. The study aims to compare the effectiveness of a 16-week progressive heavy shoulder strengthening program (HEAVY) with low-load training (LIGHT) on self-reported shoulder symptoms, function, and quality of life. The trial involves 100 patients with HSD/hEDS and shoulder complaints, with primary outcomes measured using the Western Ontario Shoulder Instability Index (WOSI). The study is designed as a superiority, parallel group, randomized controlled trial with blinded outcome assessors and participants. The primary objective is to assess the difference in self-reported shoulder-related symptoms, function, and quality of life between the HEAVY and LIGHT groups over 16 weeks. The document provides detailed information on the study protocol, intervention procedures, outcome measures, statistical analysis plans, and considerations for participant confidentiality and data integrity.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Useful for retrieving specific context from the MetaGPT paper..\n",
      "\u001b[0mLook for clinical suspicion of referred pain from the cervical spine, diagnosis of systemic inflammatory rheumatic diseases, connective tissue diseases (excluding hEDS), Marfans, Stickler's or Loeys Dietz syndromes, and/or neurological diseases. Also, consider if the patient has had shoulder surgery within the past year, received a steroid injection in the affected shoulder in the previous 3 months, or has been pregnant or given birth within the past year or planning to get pregnant during the study period due to increased levels of relaxin.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"How do I tell if a patient has EDS?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same exact code as above from utils file\n",
    "from utils import get_router_query_engine\n",
    "\n",
    "query_engine = get_router_query_engine(\"EDS.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Useful for retrieving specific context from the MetaGPT paper..\n",
      "\u001b[0mA patient may be suspected of having EDS if they exhibit symptoms such as systemic inflammatory rheumatic diseases, connective tissue diseases (excluding hEDS), or if they have been diagnosed with Marfans, Stickler's, or Loeys Dietz syndromes. Additionally, a history of shoulder surgery within the past year or a steroid injection in the affected shoulder in the previous 3 months could also indicate EDS.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How do I tell if a patient has EDS?\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
